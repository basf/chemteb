{
  "dataset_revision": "4b1018f7a60702173d5ff9c08fda4704961ca3be",
  "evaluation_time": 3.9523956775665283,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.95,
        "ap": 0.9022152193003741,
        "ap_weighted": 0.9022152193003741,
        "f1": 0.9485066593109617,
        "f1_weighted": 0.9500661074329105,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.95,
        "scores_per_experiment": [
          {
            "accuracy": 0.9081632653061225,
            "ap": 0.8163265306122449,
            "ap_weighted": 0.8163265306122449,
            "f1": 0.9073821274808358,
            "f1_weighted": 0.9089444031314091
          },
          {
            "accuracy": 0.9693877551020408,
            "ap": 0.9302325581395349,
            "ap_weighted": 0.9302325581395349,
            "f1": 0.9686533745601876,
            "f1_weighted": 0.9695346312104113
          },
          {
            "accuracy": 0.9591836734693877,
            "ap": 0.9090909090909091,
            "ap_weighted": 0.9090909090909091,
            "f1": 0.9583333333333333,
            "f1_weighted": 0.9594266277939747
          },
          {
            "accuracy": 0.9591836734693877,
            "ap": 0.9155612244897959,
            "ap_weighted": 0.9155612244897959,
            "f1": 0.9580658964484381,
            "f1_weighted": 0.9593233955970064
          },
          {
            "accuracy": 0.9285714285714286,
            "ap": 0.8787231108659681,
            "ap_weighted": 0.8787231108659681,
            "f1": 0.9251336898395721,
            "f1_weighted": 0.9280803230383061
          },
          {
            "accuracy": 0.9693877551020408,
            "ap": 0.9302325581395349,
            "ap_weighted": 0.9302325581395349,
            "f1": 0.9686533745601876,
            "f1_weighted": 0.9695346312104113
          },
          {
            "accuracy": 0.9489795918367347,
            "ap": 0.9081763474620618,
            "ap_weighted": 0.9081763474620618,
            "f1": 0.9469869090122255,
            "f1_weighted": 0.9488747137933395
          },
          {
            "accuracy": 0.9591836734693877,
            "ap": 0.9090909090909091,
            "ap_weighted": 0.9090909090909091,
            "f1": 0.9583333333333333,
            "f1_weighted": 0.9594266277939747
          },
          {
            "accuracy": 0.9387755102040817,
            "ap": 0.8934479054779807,
            "ap_weighted": 0.8934479054779807,
            "f1": 0.9361147327249022,
            "f1_weighted": 0.9385094324561638
          },
          {
            "accuracy": 0.9591836734693877,
            "ap": 0.9312701396348014,
            "ap_weighted": 0.9312701396348014,
            "f1": 0.9574098218166014,
            "f1_weighted": 0.9590062883041091
          }
        ]
      }
    ]
  },
  "task_name": "WikipediaMedium2BioluminescenceVsNeurochemistryClassification"
}