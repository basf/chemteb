{
  "dataset_revision": "907895e5fe3138626c1c8d8ff26ac90b3c447cf2",
  "evaluation_time": 2.1741931438446045,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.8695121951219512,
        "ap": 0.8128904654266208,
        "ap_weighted": 0.8128904654266208,
        "f1": 0.86899814180454,
        "f1_weighted": 0.8691982132980467,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8695121951219512,
        "scores_per_experiment": [
          {
            "accuracy": 0.8780487804878049,
            "ap": 0.8355490038416867,
            "ap_weighted": 0.8355490038416867,
            "f1": 0.8768768768768769,
            "f1_weighted": 0.8774628286823409
          },
          {
            "accuracy": 0.8170731707317073,
            "ap": 0.7316121488974087,
            "ap_weighted": 0.7316121488974087,
            "f1": 0.8168279970215935,
            "f1_weighted": 0.8165010987414415
          },
          {
            "accuracy": 0.926829268292683,
            "ap": 0.8886563717708185,
            "ap_weighted": 0.8886563717708185,
            "f1": 0.926654740608229,
            "f1_weighted": 0.926829268292683
          },
          {
            "accuracy": 0.8170731707317073,
            "ap": 0.7380058965424818,
            "ap_weighted": 0.7380058965424818,
            "f1": 0.8170459616242749,
            "f1_weighted": 0.8171547980540046
          },
          {
            "accuracy": 0.8170731707317073,
            "ap": 0.7316121488974087,
            "ap_weighted": 0.7316121488974087,
            "f1": 0.8168279970215935,
            "f1_weighted": 0.8165010987414415
          },
          {
            "accuracy": 0.9024390243902439,
            "ap": 0.8709729295095148,
            "ap_weighted": 0.8709729295095148,
            "f1": 0.9015015015015015,
            "f1_weighted": 0.9019702629458726
          },
          {
            "accuracy": 0.8780487804878049,
            "ap": 0.8093939526157337,
            "ap_weighted": 0.8093939526157337,
            "f1": 0.8780487804878049,
            "f1_weighted": 0.8780487804878049
          },
          {
            "accuracy": 0.8292682926829268,
            "ap": 0.763534641583422,
            "ap_weighted": 0.763534641583422,
            "f1": 0.8283492822966507,
            "f1_weighted": 0.8289619558875015
          },
          {
            "accuracy": 0.9390243902439024,
            "ap": 0.9019543464665416,
            "ap_weighted": 0.9019543464665416,
            "f1": 0.9389426656738644,
            "f1_weighted": 0.9390516317672484
          },
          {
            "accuracy": 0.8902439024390244,
            "ap": 0.8576132141411911,
            "ap_weighted": 0.8576132141411911,
            "f1": 0.8889056149330121,
            "f1_weighted": 0.8895004093801286
          }
        ]
      }
    ]
  },
  "task_name": "WikipediaHard2BioluminescenceVsLuminescenceClassification"
}