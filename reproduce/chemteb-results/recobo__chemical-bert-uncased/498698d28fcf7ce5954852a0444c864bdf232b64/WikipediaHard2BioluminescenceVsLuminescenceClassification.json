{
  "dataset_revision": "907895e5fe3138626c1c8d8ff26ac90b3c447cf2",
  "evaluation_time": 2.2261579036712646,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.8012195121951219,
        "ap": 0.7289244228091586,
        "ap_weighted": 0.7289244228091586,
        "f1": 0.8001323185355396,
        "f1_weighted": 0.8005492878503292,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8012195121951219,
        "scores_per_experiment": [
          {
            "accuracy": 0.8170731707317073,
            "ap": 0.7507817385866167,
            "ap_weighted": 0.7507817385866167,
            "f1": 0.8157303370786517,
            "f1_weighted": 0.8164976705946835
          },
          {
            "accuracy": 0.7926829268292683,
            "ap": 0.7135866166353971,
            "ap_weighted": 0.7135866166353971,
            "f1": 0.7924050632911392,
            "f1_weighted": 0.7927755480086446
          },
          {
            "accuracy": 0.8658536585365854,
            "ap": 0.7966437356681259,
            "ap_weighted": 0.7966437356681259,
            "f1": 0.8658337051911349,
            "f1_weighted": 0.8659135185729367
          },
          {
            "accuracy": 0.7439024390243902,
            "ap": 0.6631611862677331,
            "ap_weighted": 0.6631611862677331,
            "f1": 0.7429467084639498,
            "f1_weighted": 0.7437112929123021
          },
          {
            "accuracy": 0.7073170731707317,
            "ap": 0.6225766103814884,
            "ap_weighted": 0.6225766103814884,
            "f1": 0.7071428571428571,
            "f1_weighted": 0.706794425087108
          },
          {
            "accuracy": 0.9024390243902439,
            "ap": 0.8407289439620693,
            "ap_weighted": 0.8407289439620693,
            "f1": 0.9024390243902439,
            "f1_weighted": 0.9024390243902439
          },
          {
            "accuracy": 0.8048780487804879,
            "ap": 0.7147643297469082,
            "ap_weighted": 0.7147643297469082,
            "f1": 0.8038277511961722,
            "f1_weighted": 0.8031275528066285
          },
          {
            "accuracy": 0.7195121951219512,
            "ap": 0.6420740904241622,
            "ap_weighted": 0.6420740904241622,
            "f1": 0.7160921270510312,
            "f1_weighted": 0.7176121573047733
          },
          {
            "accuracy": 0.8902439024390244,
            "ap": 0.8488117573483426,
            "ap_weighted": 0.8488117573483426,
            "f1": 0.889438202247191,
            "f1_weighted": 0.8898986023568101
          },
          {
            "accuracy": 0.7682926829268293,
            "ap": 0.6961152190707427,
            "ap_weighted": 0.6961152190707427,
            "f1": 0.7654674093030257,
            "f1_weighted": 0.7667230864691607
          }
        ]
      }
    ]
  },
  "task_name": "WikipediaHard2BioluminescenceVsLuminescenceClassification"
}