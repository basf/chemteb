{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_results(path):\n",
    "    models_list = os.listdir(path)\n",
    "\n",
    "    times = {}\n",
    "    scores = {}\n",
    "\n",
    "    for model in models_list:\n",
    "        model_name = model.replace('__', '/')\n",
    "        scores[model_name] = {}\n",
    "        times[model_name] = {}\n",
    "\n",
    "        rev = os.listdir(os.path.join(path, model))[0]\n",
    "        tasks = os.listdir(os.path.join(path, model, rev))\n",
    "\n",
    "        for task in tasks:\n",
    "            if task in ['model_meta.json', 'CoconutRetrieval.json']:\n",
    "                continue\n",
    "            data = read_json(os.path.join(\n",
    "                path,\n",
    "                model,\n",
    "                rev,\n",
    "                task\n",
    "            ))\n",
    "            task_name = data['task_name']\n",
    "            if task_name.endswith('Classification'):\n",
    "                scores[model_name][task_name] = data['scores']['test'][0]['f1']\n",
    "            else:\n",
    "                scores[model_name][task_name] = data['scores']['test'][0]['main_score']\n",
    "\n",
    "            times[model_name][task_name] = data['evaluation_time']\n",
    "\n",
    "    return pd.DataFrame.from_dict(scores, orient='index'), pd.DataFrame.from_dict(times, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_scores(scores_df):\n",
    "    def get_category(task_name):\n",
    "        if task_name.endswith('PC'):\n",
    "            return 'PairClassification'\n",
    "        elif task_name.endswith('Classification'):\n",
    "            return 'Classification'\n",
    "        elif task_name.endswith('Retrieval'):\n",
    "            return 'Retrieval'\n",
    "        elif task_name.endswith('Clustering'):\n",
    "            return 'Clustering'\n",
    "        elif task_name.endswith('BM') or 'BitextMining' in task_name:\n",
    "            return 'BitextMining'\n",
    "\n",
    "    categories = ['PairClassification',\n",
    "                  'Classification',\n",
    "                  'BitextMining',\n",
    "                  'Retrieval',\n",
    "                  'Clustering']\n",
    "    \n",
    "    aggregated_scores = pd.DataFrame(index=scores_df.index, columns=categories)\n",
    "\n",
    "    for category in categories:\n",
    "        category_columns = [col for col in scores_df.columns if get_category(col) == category]\n",
    "\n",
    "        aggregated_scores[category] = scores_df[category_columns].mean(axis=1)\n",
    "\n",
    "    return aggregated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, times = extract_results('chemteb-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_order = ['google-bert/bert-base-uncased', 'allenai/scibert_scivocab_uncased',\n",
    "               'm3rg-iitd/matscibert', 'recobo/chemical-bert-uncased',\n",
    "               'nomic-ai/nomic-bert-2048', 'nomic-ai/nomic-embed-text-v1',\n",
    "               'nomic-ai/nomic-embed-text-v1.5', 'all-MiniLM-L6-v2',\n",
    "               'all-MiniLM-L12-v2', 'all-mpnet-base-v2',\n",
    "               'multi-qa-mpnet-base-dot-v1', 'intfloat/e5-small',\n",
    "               'intfloat/e5-base', 'intfloat/e5-large',\n",
    "               'intfloat/e5-small-v2', 'intfloat/e5-base-v2',\n",
    "               'intfloat/e5-large-v2', 'intfloat/multilingual-e5-small',\n",
    "               'intfloat/multilingual-e5-base', 'intfloat/multilingual-e5-large',\n",
    "               'BAAI/bge-small-en', 'BAAI/bge-base-en',\n",
    "               'BAAI/bge-large-en', 'BAAI/bge-small-en-v1.5',\n",
    "               'BAAI/bge-base-en-v1.5', 'BAAI/bge-large-en-v1.5',\n",
    "               'BAAI/bge-m3', 'text-embedding-3-small',\n",
    "               'text-embedding-3-large', 'text-embedding-ada-002',\n",
    "               'amazon-titan-embed-text-v2', 'amazon-titan-embed-text-v1',\n",
    "               'cohere-embed-english-v3', 'cohere-embed-multilingual-v3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['Classification', 'BitextMining', 'Retrieval',\n",
    "                'Clustering', 'PairClassification',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>BitextMining</th>\n",
       "      <th>Retrieval</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>PairClassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>google-bert/bert-base-uncased</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allenai/scibert_scivocab_uncased</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m3rg-iitd/matscibert</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recobo/chemical-bert-uncased</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai/nomic-bert-2048</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai/nomic-embed-text-v1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomic-ai/nomic-embed-text-v1.5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all-MiniLM-L6-v2</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all-MiniLM-L12-v2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all-mpnet-base-v2</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-qa-mpnet-base-dot-v1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-small</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-base</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-large</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-small-v2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-base-v2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/e5-large-v2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/multilingual-e5-small</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/multilingual-e5-base</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intfloat/multilingual-e5-large</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-small-en</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-base-en</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-large-en</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-small-en-v1.5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-base-en-v1.5</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-large-en-v1.5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAAI/bge-m3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-embedding-3-small</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-embedding-3-large</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-embedding-ada-002</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-titan-embed-text-v2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon-titan-embed-text-v1</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohere-embed-english-v3</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohere-embed-multilingual-v3</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Classification  BitextMining  Retrieval  \\\n",
       "google-bert/bert-base-uncased               0.72          0.00       0.28   \n",
       "allenai/scibert_scivocab_uncased            0.71          0.00       0.20   \n",
       "m3rg-iitd/matscibert                        0.70          0.00       0.11   \n",
       "recobo/chemical-bert-uncased                0.68          0.00       0.17   \n",
       "nomic-ai/nomic-bert-2048                    0.67          0.00       0.05   \n",
       "nomic-ai/nomic-embed-text-v1                0.77          0.00       0.72   \n",
       "nomic-ai/nomic-embed-text-v1.5              0.78          0.00       0.75   \n",
       "all-MiniLM-L6-v2                            0.78          0.00       0.61   \n",
       "all-MiniLM-L12-v2                           0.77          0.00       0.58   \n",
       "all-mpnet-base-v2                           0.78          0.00       0.56   \n",
       "multi-qa-mpnet-base-dot-v1                  0.74          0.00       0.56   \n",
       "intfloat/e5-small                           0.75          0.00       0.69   \n",
       "intfloat/e5-base                            0.76          0.00       0.68   \n",
       "intfloat/e5-large                           0.77          0.00       0.70   \n",
       "intfloat/e5-small-v2                        0.76          0.00       0.69   \n",
       "intfloat/e5-base-v2                         0.76          0.00       0.68   \n",
       "intfloat/e5-large-v2                        0.76          0.00       0.73   \n",
       "intfloat/multilingual-e5-small              0.74          0.00       0.76   \n",
       "intfloat/multilingual-e5-base               0.75          0.00       0.68   \n",
       "intfloat/multilingual-e5-large              0.74          0.00       0.67   \n",
       "BAAI/bge-small-en                           0.78          0.00       0.52   \n",
       "BAAI/bge-base-en                            0.77          0.00       0.59   \n",
       "BAAI/bge-large-en                           0.78          0.00       0.44   \n",
       "BAAI/bge-small-en-v1.5                      0.78          0.00       0.63   \n",
       "BAAI/bge-base-en-v1.5                       0.77          0.00       0.69   \n",
       "BAAI/bge-large-en-v1.5                      0.78          0.00       0.67   \n",
       "BAAI/bge-m3                                 0.76          0.00       0.68   \n",
       "text-embedding-3-small                      0.78          0.00       0.65   \n",
       "text-embedding-3-large                      0.80          0.01       0.71   \n",
       "text-embedding-ada-002                      0.78          0.00       0.66   \n",
       "amazon-titan-embed-text-v2                  0.77          0.00       0.62   \n",
       "amazon-titan-embed-text-v1                  0.81          0.00       0.60   \n",
       "cohere-embed-english-v3                     0.81          0.00       0.49   \n",
       "cohere-embed-multilingual-v3                0.80          0.00       0.49   \n",
       "\n",
       "                                  Clustering  PairClassification  \n",
       "google-bert/bert-base-uncased           0.20                0.41  \n",
       "allenai/scibert_scivocab_uncased        0.18                0.43  \n",
       "m3rg-iitd/matscibert                    0.21                0.41  \n",
       "recobo/chemical-bert-uncased            0.13                0.42  \n",
       "nomic-ai/nomic-bert-2048                0.22                0.38  \n",
       "nomic-ai/nomic-embed-text-v1            0.46                0.55  \n",
       "nomic-ai/nomic-embed-text-v1.5          0.50                0.55  \n",
       "all-MiniLM-L6-v2                        0.36                0.54  \n",
       "all-MiniLM-L12-v2                       0.34                0.54  \n",
       "all-mpnet-base-v2                       0.50                0.54  \n",
       "multi-qa-mpnet-base-dot-v1              0.42                0.54  \n",
       "intfloat/e5-small                       0.12                0.48  \n",
       "intfloat/e5-base                        0.34                0.49  \n",
       "intfloat/e5-large                       0.51                0.50  \n",
       "intfloat/e5-small-v2                    0.19                0.46  \n",
       "intfloat/e5-base-v2                     0.38                0.47  \n",
       "intfloat/e5-large-v2                    0.33                0.48  \n",
       "intfloat/multilingual-e5-small          0.17                0.47  \n",
       "intfloat/multilingual-e5-base           0.48                0.47  \n",
       "intfloat/multilingual-e5-large          0.30                0.48  \n",
       "BAAI/bge-small-en                       0.27                0.48  \n",
       "BAAI/bge-base-en                        0.44                0.48  \n",
       "BAAI/bge-large-en                       0.45                0.49  \n",
       "BAAI/bge-small-en-v1.5                  0.25                0.48  \n",
       "BAAI/bge-base-en-v1.5                   0.47                0.49  \n",
       "BAAI/bge-large-en-v1.5                  0.39                0.50  \n",
       "BAAI/bge-m3                             0.45                0.47  \n",
       "text-embedding-3-small                  0.49                0.50  \n",
       "text-embedding-3-large                  0.60                0.53  \n",
       "text-embedding-ada-002                  0.52                0.49  \n",
       "amazon-titan-embed-text-v2              0.49                0.49  \n",
       "amazon-titan-embed-text-v1              0.45                0.49  \n",
       "cohere-embed-english-v3                 0.55                0.53  \n",
       "cohere-embed-multilingual-v3            0.53                0.53  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_agg = aggregate_scores(scores)\n",
    "scores_agg = scores_agg.reindex(index_order)\n",
    "scores_agg = scores_agg[column_order]\n",
    "scores_agg.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
